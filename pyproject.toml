[project]
name = "diffusionlm"
version = "1.0.0"
description = "Diffusion LM mini stack: from-scratch core with tokenizer, streaming data, CLI, and lightweight benchmarks."
readme = "README.md"
requires-python = ">=3.11,<3.13"
dependencies = [
    "numpy",
    "pytest>=8.3.4",
    "jaxtyping>=0.3.0",
    "torch",
    "tqdm>=4.67.1",
    "wandb>=0.19.7",
    "einops>=0.8.1",
    "regex>=2024.11.6",
    "datasets>=3.0.1",
    "pydantic>=2.10",
]

[tool.uv]
python-preference = "managed"

[tool.ruff]
line-length = 120

[tool.ruff.lint]
extend-select = ["UP"]
ignore = [
    "F722"
]

[project.scripts]
diffusionlm-train = "cli.train:main"
diffusionlm-infer = "cli.infer:main"
diffusionlm-make-data = "cli.make_data:main"
diffusionlm-train-tokenizer = "cli.train_tokenizer:main"
diffusionlm-bench-infer = "benchmarking.bench_infer_latency:main"
diffusionlm-bench-tokenizer = "benchmarking.bench_tokenizer:main"

[build-system]
requires = ["maturin>=1.7,<2"]
build-backend = "maturin"

[tool.maturin]
bindings = "pyo3"
module-name = "diffusionlm.tokenizer_rust"
python-source = "."
manifest-path = "diffusionlm/tokenizer_rust/Cargo.toml"

[tool.pytest.ini_options]
addopts = ["-q"]
markers = [
  "slow: marks tests as slow (deselect with '-m \"not slow\"')",
  "gpu: requires CUDA/GPU",
  "cpu: requires only CPU resources",
]
