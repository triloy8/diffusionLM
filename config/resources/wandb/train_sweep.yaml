program: cli/sweep_train.py
project: diffusion_muon_lr_simplestories
command:
  - ${env}
  - uv
  - run
  - diffusionlm-sweep-train
  - --config
  - config/resources/train.toml
method: bayes
metric:
  goal: minimize
  name: metrics.val_loss
parameters:
  logging.architecture:
    value: DiffusionLM
  logging.dataset:
    value: SimpleStories
  training.batch_size:
    value: 128
  training.objective:
    value: diffusion
  training.max_train_iteration:
    value: 1000
  training.max_val_iteration:
    value: 10
  training.val_freq_iteration:
    value: 100
  training.grad_accum_steps:
    value: 1
  checkpointing.ckpting_save_iter:
    value: 1000
  model.context_length:
    value: 512
  model.d_ff:
    value: 2048
  model.d_model:
    value: 512
  model.num_layers:
    value: 12
  model.num_heads:
    value: 8
  model.rope_theta:
    value: 10000.0
  model.attention_backend:
    value: torch_sdpa
  model.attention_sdp_backend:
    value: flash
  data.dataset_name:
    value: SimpleStories/SimpleStories
  data.dataset_config:
    value: ""
  data.train_split:
    value: train
  data.val_split:
    value: test
  data.text_field:
    value: story
  data.pipeline_mode:
    value: packed
  data.pad_token_id:
    value: 50256
  data.pad_random_shift:
    value: false
  data.shuffle_buffer_size:
    value: 0
  data.shuffle_seed:
    value: 3407
  model.device:
    value: cuda
  model.dtype:
    value: float32
  model.vocab_size:
    value: 8001
  model.eot_token_id:
    value: 7999
  model.mask_token_id:
    value: 8000
  model.noise_epsilon:
    value: 0.001
  model.random_trunc_prob:
    value: 0.0
  optimizer.optimizer_name:
    value: muon
  optimizer.betas:
    value: [0.9, 0.95]
  optimizer.eps:
    value: 1e-8
  optimizer.weight_decay:
    value: 0.0
  optimizer.grad_clip_max_l2_norm:
    value: 3.0
  optimizer.lr_schedule:
    value: constant_with_warmup
  optimizer.cosine_cycle_iters:
    value: 60000
  optimizer.warmup_iters:
    value: 100
  optimizer.muon.hidden.initial_learning_rate:
    value: 0.01
  optimizer.muon.hidden.min_learning_rate:
    value: 0.0014
  optimizer.muon.hidden.max_learning_rate:
    distribution: log_uniform_values
    min: 0.008
    max: 0.03
  optimizer.muon.hidden.momentum:
    value: 0.90
  optimizer.muon.hidden.weight_decay:
    value: 0.01
  optimizer.muon.head.initial_learning_rate:
    value: 0.003
  optimizer.muon.head.min_learning_rate:
    value: 0.0003
  optimizer.muon.head.max_learning_rate:
    distribution: log_uniform_values
    min: 0.0015
    max: 0.006
  optimizer.muon.head.betas:
    value: [0.9, 0.95]
  optimizer.muon.head.eps:
    value: 1e-10
  optimizer.muon.head.weight_decay:
    value: 0.02
  optimizer.muon.embed.initial_learning_rate:
    value: 0.01
  optimizer.muon.embed.min_learning_rate:
    value: 0.0023
  optimizer.muon.embed.max_learning_rate:
    distribution: log_uniform_values
    min: 0.01
    max: 0.04
  optimizer.muon.embed.betas:
    value: [0.9, 0.95]
  optimizer.muon.embed.eps:
    value: 1e-10
  optimizer.muon.embed.weight_decay:
    value: 0.01
  optimizer.muon.scalar.initial_learning_rate:
    value: 0.0008
  optimizer.muon.scalar.min_learning_rate:
    value: 0.00004
  optimizer.muon.scalar.max_learning_rate:
    distribution: log_uniform_values
    min: 0.0004
    max: 0.002
  optimizer.muon.scalar.betas:
    value: [0.9, 0.95]
  optimizer.muon.scalar.eps:
    value: 1e-10
  optimizer.muon.scalar.weight_decay:
    value: 0.02
